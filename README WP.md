[# Шаблон backend сервера на Golang — часть 5 - Worker pool](https://habr.com/ru/post/720286/)

[//]: # (![Схема развертывания в Kubernetes]&#40;https://github.com/romapres2010/goapp/raw/master/doc/diagram/APP%20-%20Kebernates.jpg&#41;)

[Первая часть](https://habr.com/ru/post/492062/) шаблона была посвящена HTTP серверу.

[Вторая часть](https://habr.com/ru/post/500554/) шаблона была посвящена прототипированию REST API.

[Третья часть](https://habr.com/ru/post/716634/) посвящена развертыванию шаблона в Docker, Docker Compose, Kubernetes (kustomize).

Четвертая часть будет посвящена развертыванию в Kubernetes с Helm chart и настройке Horizontal Autoscaler.

[Пятая часть](https://habr.com/ru/post/720286/) посвящена простому Worker pool.

При развертывании приложения в Kubernetes столкнулись с особенностями.
- при росте нагрузки Horizontal Autoscaler (HA) может создавать новые Pod c приложением и перенаправлять на него часть запросов.
- при снижении нагрузки (по памяти или загрузке процессора), Horizontal Autoscaler останавливает Pod c приложением.   

В нашем приложении Worker pool, использовался для двух типов задач: 
- высоконагруженных расчетов с периодической нагрузкой
- длительных (1-30 сек) и слабонагруженных задач взаимодействия с внешними сервисами   

В периоды высокой нагрузки, Horizontal Autoscaler создавал 2-5 новых Pod, а через 30-60 минут удалял ненужные. Pod останавливаются произвольным образом, в результате мы получали обрывы соединений и отказ в обслуживании для длительных операции. 

Правильный вариант решения такой проблемы - это разнесение разных типов задач на разные микросервисы. Но вместе с этим, пришлось серьезно перепроектировать Worker pool.

Представленный в шаблоне Worker pool дополнительно реализует следующую функциональность:
- Возможность экстренной остановки Worker pool в целом 
  - явно по команде остановки
  - автоматически по закрытию корневого контекста
  - контроль timeout остановки работающих worker
- Возможность экстренной остановки отдельного worker
  - явно по команде остановки (жесткий режим или с ожиданием завершения текущей task)
  - автоматически по закрытию корневого контекста
- Возможность экстренной остановки отдельного task
  - явно по команде остановки
  - по предельному таймауту
- Автоматический перезапуск сбойного worker
- Сбор метрик [prometheus](https://prometheus.io/) по загрузке worker, очереди задач и производительности выполнения по типам task
- Возможность управления группами task в рамках единого Worker pool
- Накладные расходы Worker pool для одной task 500-900 ns/op, от60 B/op, от 2 allocs/op

Ссылка на [репозиторий проекта](https://github.com/romapres2010/goapp).

Шаблон goapp в репозитории полностью готов к развертыванию в Docker, Docker Compose, Kubernetes (kustomize), Kubernetes (helm).

## Содержание
1. Архитектура Worker pool
2. Подходы к остановке приложения (микросервиса)
3. Структура Task
4. Настройка Worker pool через конфиг
5. Оптимизация накладных расходов Worker pool
6. Пример использования Worker pool
7. Нагрузочное тестирование Worker pool
 
<cut />

## . Архитектура Worker pool
В основе лежит концепция из статьи [Ahad Hasan](https://hackernoon.com/concurrency-in-golang-and-workerpool-part-2-l3w31q7). 

## . Подходы к остановке приложения (микросервиса) 
Условно, можно выделить подходы к остановке приложения:
- "Light" - все начатые к обработке и все взятые в очередь задачи должны быть завершены, новые задачи не принимаются. Потребители по новым запросам получают отказ в обслуживании.
- "Soft" - только начатые к обработке задачи должны быть завершены, новые задачи не принимаются, оставшиеся в очереди задачи останавливаются с ошибкой. Потребители по новым запросам и запросам не начатым обрабатываться получают отказ в обслуживании.
- "Soft + timeout" - сначала отрабатывает "Soft", если не уложились в timeout, то срабатывает "Hard".   
- "Hard" - экстренно прерывается обработка всех задач, как начатых, так и находящихся в очереди. Потребители получают отказ в обслуживании. 
- "Crash" - приложение удаляется KILL -9. Сетевые соединения разрываются. Потребители не получают дополнительной информации кроме разрыва соединения.

Если приложение stateless, то, желательно использовать подход "Crash" или "Hard". Потребители всегда смогут отправить повторные запросы и их обработает другой Pod.

Если приложение stateful, то, если завершить начатые задачи невозможно в режиме "soft", то нужно сделать пометку о необходимости компенсационного действия. Компенсационные действия может выполнять само приложение при повторном запуске, либо отдельный служебный сервис.  

Шаблон Worker pool в репозитории поддерживается варианты остановки "Light", "Soft", "Soft + timeout", "Hard". по умолчанию настроен режим "Hard". 

## . Структура Task

[Task](https://github.com/romapres2010/goapp/blob/master/pkg/common/workerpool/task.go) - содержит входные параметры задачи, функцию обработчик, результаты выполнения, каналы для управления и таймер для контроля timeout.

Основные задачи Task:
- Запустить функцию-обработчик и передать ей входные данные
- Контролировать результат выполнения функции-обработчика
- Информировать "внешний мир" о завершении выполнения функции-обработчика
- Контролировать время выполнения функции-обработчика по timeout, при необходимости прервать выполнение
- Перехватить panic от функции-обработчика и обработать ошибку
- Контролировать команду на остановку со стороны Worker pool
- Информировать функцию-обработчика о необходимости срочной остановки

``` go
type Task struct {
	parentCtx context.Context    // родительский контекст, переданный при создании task
	ctx       context.Context    // контекст, в рамках которого работает task
	cancel    context.CancelFunc // функция закрытия контекста для task

	externalId  uint64             // внешний идентификатор, в рамках которого работает task
	doneCh      chan<- interface{} // канал сигнала о завершении выполнения задачи
	stopCh      chan interface{}   // канал остановки task, запущенного в фоне
	localDoneCh chan interface{}   // локальный канал task о завершении задачи

	id      uint64        // номер task
	state   TaskState     // состояние жизненного цикла task
	name    string        // наименование task для логирования
	timeout time.Duration // максимальное время выполнения task
	timer   *time.Timer   // таймер остановки по timeout

	requests  []interface{} // входные данные task
	responses []interface{} // результаты task
	err       error         // ошибки task

	duration time.Duration // реальная длительность выполнения task

	f func(context.Context, context.Context, ...interface{}) (error, []interface{}) // функция обработчик task

	mx sync.RWMutex
}
}
```

Task управляется следующей статусной моделью.
``` go
type TaskState int

const (
	TASK_STATE_NEW                    TaskState = iota // task создан
	TASK_STATE_IN_PROCESS                              // task выполняется
	TASK_STATE_DONE_SUCCESS                            // task завершился
	TASK_STATE_RECOVER_ERR                             // task остановился из-за паники
	TASK_STATE_TERMINATED_STOP_SIGNAL                  // task остановлен по причине получения сигнала об остановке
	TASK_STATE_TERMINATED_CTX_CLOSED                   // task остановлен по причине закрытия контекста
	TASK_STATE_TERMINATED_TIMEOUT                      // task остановлен по причине превышения timeout
)
```
